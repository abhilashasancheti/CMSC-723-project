{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\"\"\"\n",
    "<doc id=650677>\n",
    "\t<EN-summary>\n",
    "\t\tThink of the Internet of Things: Sci-fi scripts in life\n",
    "\t</EN-summary>\n",
    "\t<EN-summary-human-corrected>\n",
    "\t\tthink of the internet of things : sci-fi scripts in life\n",
    "\t</EN-summary-human-corrected>\n",
    "\t<Back-Translated-ZH-summary>\n",
    "\t\t想想物联网：生活中的科幻剧本\n",
    "\t</Back-Translated-ZH-summary>\n",
    "</doc>\n",
    "\"\"\"\n",
    "def test_data_parse(filename):\n",
    "    test_source_document_ids = []\n",
    "    test_summary_english = []\n",
    "    xml = open(filename)\n",
    "    datapoint = BeautifulSoup(xml).findAll('doc')\n",
    "    for doc in datapoint:\n",
    "        test_source_document_ids.append(doc['id'])\n",
    "        test_summary_english.append(doc.find('en-summary-human-corrected').text.lower().strip())\n",
    "    return test_source_document_ids, test_summary_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid and train dataset\n",
    "\"\"\"\n",
    "<doc id=1284817>\n",
    "\t<EN-summary>\n",
    "\t\tCommunication, a lifeline that cannot be interrupted\n",
    "\t</EN-summary>\n",
    "\t<Back-Translated-ZH-summary>\n",
    "\t\t通信，一条不可中断的生命线\n",
    "\t</Back-Translated-ZH-summary>\n",
    "</doc>\n",
    "\"\"\"\n",
    "def train_valid_data_parse(filename):\n",
    "    train_source_document_ids = []\n",
    "    train_summary_english = []\n",
    "    xml = open(filename)\n",
    "    datapoint = BeautifulSoup(xml).findAll('doc')\n",
    "    xml.close()\n",
    "    for doc in datapoint:\n",
    "        train_source_document_ids.append(doc['id'])\n",
    "        train_summary_english.append(doc.find('en-summary').text.lower().strip())\n",
    "    return train_source_document_ids, train_summary_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCSTS dataset\n",
    "\"\"\"\n",
    "<doc id=650677>\n",
    "    <summary>\n",
    "        物联网随想：生活中的科幻剧本\n",
    "    </summary>\n",
    "    <short_text>\n",
    "        你走到家门口，大门识别到你口袋里的密匙卡，为你自动解锁。外面很冷，但是门的另一边却是温暖舒适的23度，因为恒温器根据你离家的距离计算出你回家所需时间，提前点燃了壁炉。随着你踏入室内，嵌入式地灯照亮了通往厨房的道路。\n",
    "    </short_text>\n",
    "</doc>\n",
    "\"\"\"\n",
    "def read_source_document(filename):\n",
    "    documents_dic = {}\n",
    "    xml = open(filename,'r')\n",
    "    documents = BeautifulSoup(xml).findAll('doc')\n",
    "    xml.close()\n",
    "    for doc in documents:\n",
    "        doc_id = doc['id']\n",
    "        if doc_id not in documents_dic:\n",
    "            documents_dic[doc_id] = {}\n",
    "            documents_dic[doc_id]['article'] = doc.find('short_text').text.strip()\n",
    "            documents_dic[doc_id]['summary'] = doc.find('summary').text.strip()\n",
    "    return documents_dic\n",
    "\n",
    "def source_document_parse(documents_dic, document_ids):\n",
    "    source_document = []\n",
    "    summary_chinese = []\n",
    "    for doc_id in document_ids:\n",
    "        source_document.append(documents_dic[doc_id]['article'])\n",
    "        summary_chinese.append(documents_dic[doc_id]['summary'])\n",
    "    return source_document, summary_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(source_document, summary_english, summary_chinese, phase):\n",
    "    # write source document file\n",
    "    with open('data/raw/'+phase+'.source.txt','w') as f:\n",
    "        for doc in source_document:\n",
    "            f.write('{}\\n'.format(doc.strip()))\n",
    "    # write english summary file\n",
    "    with open('data/raw/'+phase+'.summary.en.txt','w') as f:\n",
    "        for summary in summary_english:\n",
    "            f.write('{}\\n'.format(summary.replace('\\n','').lower().strip()))\n",
    "    # write chinese summary file\n",
    "    with open('data/raw/'+phase+'.summary.zh.txt','w') as f:\n",
    "        for summary in summary_chinese:\n",
    "            f.write('{}\\n'.format(summary.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source_document_ids, test_summary_english = test_data_parse('./test/ZH2ENSUM_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_document_ids, train_summary_english = train_valid_data_parse('./drive-download-20191111T160803Z-001/ZH2ENSUM_train.txt')\n",
    "valid_source_document_ids,valid_summary_english = train_valid_data_parse('./drive-download-20191111T160803Z-001/ZH2ENSUM_valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dic = {}\n",
    "filename='./LCSTS2.0/DATA/PART_I.txt'\n",
    "xml = open(filename,'r')\n",
    "documents = BeautifulSoup(xml).findAll('doc')\n",
    "xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400591"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='./LCSTS2.0/DATA/PART_1a.txt'\n",
    "xml = open(filename,'r')\n",
    "documents2 = BeautifulSoup(xml).findAll('doc')\n",
    "xml.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319379"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.extend(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly setting documents with id 2081211 because it contains ampersand and we are reading the file as html \n",
    "# which does not read &\n",
    "markup = '''<doc id=2081211>\n",
    "    <summary>\n",
    "        RIRI&amp;#M.A.C#圣诞限量彩妆系列\n",
    "    </summary>\n",
    "    <short_text>\n",
    "        今个系列特别推出指甲油、亮泽防水眼线液、炫目珍珠眼影组合、古铜蜜粉饼，与及双头设计的眼影扫。以独特的珍珠白色为包装，与RiRi签名的玫瑰金装饰细节点缀。12月13日限量登场！\n",
    "    </short_text>\n",
    "</doc>'''\n",
    "soup = BeautifulSoup(markup)\n",
    "documents[2081211]=soup.find('doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dic = {}\n",
    "for doc in documents:\n",
    "    doc_id = doc['id']\n",
    "    if doc_id not in documents_dic:\n",
    "        documents_dic[doc_id] = {}\n",
    "        documents_dic[doc_id]['article'] = doc.find('short_text').text.strip()\n",
    "        documents_dic[doc_id]['summary'] = doc.find('summary').text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing raw data in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating raw train files\n",
    "train_source_document, train_summary_chinese = source_document_parse(documents_dic, train_source_document_ids)\n",
    "write_files(train_source_document, train_summary_english, train_summary_chinese, 'train')\n",
    "# creating raw validation files\n",
    "valid_source_document, valid_summary_chinese = source_document_parse(documents_dic, valid_source_document_ids)\n",
    "write_files(valid_source_document, valid_summary_english, valid_summary_chinese, 'valid')\n",
    "# creating raw test files\n",
    "test_source_document, test_summary_chinese = source_document_parse(documents_dic, test_source_document_ids)\n",
    "write_files(test_source_document, test_summary_english, test_summary_chinese, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('documents_dic.pkl','wb') as f:\n",
    "    pickle.dump(documents_dic,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents_dic.pkl','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dic = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_document_ids, train_summary_english = train_valid_data_parse('./test/ZH2ENSUM_train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1693713"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_summary_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_source_document, train_summary_chinese = source_document_parse(documents_dic, train_source_document_ids)\n",
    "train_source_document, train_summary_chinese = [],[]\n",
    "write_files(train_source_document, train_summary_english, train_summary_chinese, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
